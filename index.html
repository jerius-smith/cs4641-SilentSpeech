<!DOCTYPE html>
<html lang="en">
<head>
    <title>CS 4641 - Silent Speech</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="index.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"></script>
</head>
<header>
    <div class="container-fluid p-3 my-3 bg-dark text-white">
        <h1>Silent Speller</h1>
        <p>CS 4641 Spring 2020</p>
    </div>
</header>
<body>
  <div class="info">
    <h2>Introduction</h2>
     <p>We created a silent spelling system that aims to recognize language from silent utterances. This system is useful for people
         with speech impairments, for people in noisy environments, and for people in social situations that restrict speech. Speech
         impairments may result from ALS, tracheostomies, or deafness. Noisy environments limit the effectivess of conversational AI.
         Social situations, like lectures or meetings, may require a subtler interface than speech. Additionally, silent speech
         systems provide more privacy for sharing information than speech. Researchers have explored using different sensors, like
         surface electromyography and video, to capture data that encodes speech. We further existing research on speech recognition
         by using Hidden Markov Models to recognize silent utterances at the letter level, and increase the accuracy of our recognizer
         by introducing context training and a statistical grammar.
     </p>
      <div class="figures">
          <div class="figure">
              <img src="./res/SmartPalate.png" height="450" width="450">
              <p>Figure 1: SmartPalate Device</p>
          </div>
      </div>
      <h2>Related Works</h2>
    </div>
    <div class="info">
        <h2>Experimental Design</h2>
        <p>The SmartPalate is a retainer fitted with 124 capacitive sensors. Each sensor records a zero or one at a frequency
            of 100Hz. The SmartPalate was used by an individual to collect two datasets. The first dataset consisted of 20 samples
            of each letter of the alphabet. The second dataset consisted of 10 samples of 10 phrases from the Mackenzie phrase set,
            that were constructed from the best recognized letters from the first dataset. The algorithm used to classify the first
            dataset was a Hidden Markov Model. The algorithm used to classify the second dataset was a Hidden Markov Model with
            context training and a statistical grammar.
        </p>
        <div class="figures">
            <div class="inlineFigurefigure">
                <img src="./res/A1.png" height="288" width="432">
                <p>Figure 2-1: Visualization of activated capacitive sensors from the first sample of the letter "A"</p>
            </div>
            <div class="inlineFigurefigure">
                <img src="./res/B1.png" height="288" width="432">
                <p>Figure 2-2: Visualization of activated capacitive sensors from the first sample of the letter "B"</p>
            </div>
            <div class="inlineigure">
                <img src="./res/C1.png" height="288" width="432">
                <p>Figure 2-2: Visualization of activated capacitive sensors from the first sample of the letter "C"</p>
            </div>
        </div>
    </div>
    <div class="info">
        <h2></h2>
        <p></p>
    </div>
    <p class="info">
        <h2>Conclusion and Future Work</h2>
      <h2>Evaluation</h2>
        <p>The accuracy of our models were determined by its offline classification performance.</p>
        <h2>References</h2>
        <ol>

            <li>R. Lee, J Wu, and T. Starner. TongueBoard: An Oral Interface for Subtle Input. In Proceedings of the 10th Augmented Human International Conference 2019. ACM, New York, NY, USA.</li>
            <li>N. Kimura, M. Kono, and J. Rekimoto. 2019. SottoVoce: An Ultrasound Imaging-Based Silent Speech Interaction Using Deep Neural Networks. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI â€˜19). ACM, New York, NY, USA, 1 -- 11.</li>
            <li>Jelinek, F.; Bahl, L.; Mercer, R. (1975). "Design of a linguistic statistical decoder for the recognition of continuous speech". IEEE Transactions on Information Theory. 21 (3): 250.</li>
            <li>S.J. Young and Sj Young. The HTK Hidden Markov Model Toolkit: Design and Philosophy. Entropic Cambridge Research Laboratory, Ltd 1994. 2--44.</li>
            <li>Xuedong Huang; M. Jack; Y. Ariki (1990). Hidden Markov Models for Speech Recognition. Edinburgh University Press. ISBN 978-0-7486-0162-2.</li>
            <li>B. Denby, T. Schultz, K. Honda, T. Hueber, J. M. Gilbert, and J. S. Brumberg. 2010. Silent Speech Interfaces. Speech Commun. 52, 4 (April 2010), 270--287.</li>
            <li>Diandra Fabre, Thomas Hueber, Laurent Girin, Xavier Alameda-Pineda, and Pierre Badin. 2017. Automatic animation of an articulatory tongue model from ultrasound images of the vocal tract. Speech Communication 93 (2017), 63 -- 75.</li>
            <li>M.J. Fagan, S.R. Ell, J.M. Gilbert, E. Sarrazin, and P.M. Chapman. 2008. Development of a (silent) speech recognition system for patients following laryngectomy. Medical Engineering & Physics 30, 4 (2008), 419 -- 425.</li>
            <li>Masaaki Fukumoto. 2018. SilentVoice: Unnoticeable Voice Input by Ingressive Speech. In Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology (UIST '18). ACM, New York, NY, USA, 237--246.</li>
            <li>MacKenzie, I. S., & Soukoreff, R. W. (2003). Phrase sets for evaluating text entry techniques. Extended Abstracts of the ACM Conference on Human Factors in Computing Systems - CHI 2003, pp. 754-755. New York: ACM.</li>

        </ol>
    </div>
</body>
</html>
